{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96943c83",
   "metadata": {},
   "source": [
    "# 0. Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "346a26fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./tfdet\"):\n",
    "    !git clone -q http://github.com/burf/tfdetection.git\n",
    "    !mv ./tfdetection/tfdet ./tfdet\n",
    "    !rm -rf ./tfdetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6d570c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore warning\n",
    "import warnings, os\n",
    "warnings.filterwarnings(action = \"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "import tfdet\n",
    "#tfdet.core.util.set_seed(777) #set seed\n",
    "device = tfdet.core.util.select_device(0) #set device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621c4f59",
   "metadata": {},
   "source": [
    "# 1. Init Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8729733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "image_shape = [32, 32]\n",
    "label = [\"OK\", \"NG\"]\n",
    "train_size = 1000\n",
    "val_size = 100\n",
    "test_size = 100\n",
    "batch_size = 16\n",
    "\n",
    "def preprocess(x_true, y_true = None):\n",
    "    x_true = np.expand_dims(x_true, axis = -1)\n",
    "    x_true = np.tile(x_true, [1, 1, 3])\n",
    "    if y_true is None:\n",
    "        return x_true\n",
    "    else:\n",
    "        return x_true, y_true\n",
    "    \n",
    "(tr_x, tr_y), (te_x, te_y) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "tr_dataset = tfdet.dataset.Dataset(tr_x[tr_y == 0][:train_size],\n",
    "                                   transform = [preprocess, #for mnist (28, 28) > (28, 28, 3)\n",
    "                                                {\"name\":\"load\"}, #image is file\n",
    "                                                {\"name\":\"resize\", \"image_shape\":image_shape},\n",
    "                                                {\"name\":\"normalize\", \"mean\":[123.675, 116.28, 103.53], \"std\":[58.395, 57.12, 57.375]},\n",
    "                                                {\"name\":\"pad\", \"image_shape\":image_shape, \"pad_val\":0}])\n",
    "\n",
    "val_y = np.expand_dims((te_y[:val_size] != 0).astype(np.int32), axis = -1) #0 is ok, etc is ng.\n",
    "val_dataset = tfdet.dataset.Dataset(te_x[:val_size],\n",
    "                                    transform = [preprocess, #for mnist (28, 28) > (28, 28, 3)\n",
    "                                                 {\"name\":\"load\"}, #image is file\n",
    "                                                 {\"name\":\"resize\", \"image_shape\":image_shape},\n",
    "                                                 {\"name\":\"normalize\", \"mean\":[123.675, 116.28, 103.53], \"std\":[58.395, 57.12, 57.375]},\n",
    "                                                 {\"name\":\"pad\", \"image_shape\":image_shape, \"pad_val\":0}])\n",
    "\n",
    "te_y = np.expand_dims((te_y[val_size:val_size + test_size] != 0).astype(np.int32), axis = -1) #0 is ok, etc is ng.\n",
    "te_dataset = tfdet.dataset.Dataset(te_x[val_size:val_size + test_size],\n",
    "                                   transform = [preprocess, #for mnist (28, 28) > (28, 28, 3)\n",
    "                                                {\"name\":\"load\"}, #image is file\n",
    "                                                {\"name\":\"resize\", \"image_shape\":image_shape},\n",
    "                                                {\"name\":\"normalize\", \"mean\":[123.675, 116.28, 103.53], \"std\":[58.395, 57.12, 57.375]},\n",
    "                                                {\"name\":\"pad\", \"image_shape\":image_shape, \"pad_val\":0}])\n",
    "\n",
    "tr_pipe = tfdet.dataset.PipeLoader(tr_dataset, batch_size = batch_size, prefetch = True)\n",
    "val_pipe = tfdet.dataset.PipeLoader(val_dataset, batch_size = batch_size, prefetch = True)\n",
    "te_pipe = tfdet.dataset.PipeLoader(te_dataset, batch_size = batch_size, prefetch = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872ea27f",
   "metadata": {},
   "source": [
    "# 2. Build Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0e2ae86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 3s 34ms/step\n"
     ]
    }
   ],
   "source": [
    "with device:\n",
    "    x = tf.keras.layers.Input(shape = [*image_shape, 3])\n",
    "    out = tfdet.model.backbone.wide_resnet50_2(x, weights = \"imagenet_v2\", indices = [0, 1, 2])\n",
    "    model = tf.keras.Model(x, out)\n",
    "    feature = model.predict(tr_pipe, verbose = 1) #feature extract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932716e4",
   "metadata": {},
   "source": [
    "# 3. Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b313dd",
   "metadata": {},
   "source": [
    "3-1. Init HyperParameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "608c8f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_size = 550\n",
    "memory_reduce = True\n",
    "\n",
    "n_feature = np.sum([np.shape(f)[-1] for f in feature])\n",
    "sampling_index = np.random.choice(np.arange(n_feature), sampling_size, replace = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dd4df7",
   "metadata": {},
   "source": [
    "3-2. Generate Feature Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96582a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with device:\n",
    "    feature_vector = tfdet.model.train.padim.train(feature, sampling_index = sampling_index, memory_reduce = memory_reduce) #memory_reduce is a tradeoff between accuracy and memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dda88c",
   "metadata": {},
   "source": [
    "3-3. Build Predict Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4bdaf31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 43ms/step\n"
     ]
    }
   ],
   "source": [
    "with device:\n",
    "    out = tfdet.model.detector.padim(out, feature_vector, image_shape = image_shape, sampling_index = sampling_index, memory_reduce = memory_reduce) #align memory_reduce with train in test\n",
    "    model = tf.keras.Model(x, out)\n",
    "    score_pred, mask_pred = model.predict(val_pipe, verbose = 1)\n",
    "    threshold = tfdet.util.get_threshold(val_y, score_pred)\n",
    "    filtered_out = tfdet.model.postprocess.padim.FilterDetection(threshold = threshold)(out)\n",
    "    model = tf.keras.Model(x, filtered_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae5c70b",
   "metadata": {},
   "source": [
    "# 4. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "567f6e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score : 0.9900\n"
     ]
    }
   ],
   "source": [
    "score_pred, mask_pred = model.predict(te_pipe, verbose = 0)\n",
    "print(\"score : {0:.4f}\".format(np.mean((0 < score_pred) == te_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bc37af",
   "metadata": {},
   "source": [
    "# 5. Save & Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bd5e4a",
   "metadata": {},
   "source": [
    "5-1. Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65f06bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./learn/model.pickle'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, shutil, pickle\n",
    "\n",
    "save_path = \"./learn/model.pickle\"\n",
    "\n",
    "if os.path.exists(os.path.dirname(save_path)):\n",
    "    shutil.rmtree(os.path.dirname(save_path))\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok = True)\n",
    "\n",
    "tfdet.dataset.util.save_pickle([image_shape, feature_vector, sampling_index, memory_reduce, threshold], save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c183c431",
   "metadata": {},
   "source": [
    "5-2. Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93a4ccd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score : 0.9900\n"
     ]
    }
   ],
   "source": [
    "save_path = \"./learn/model.pickle\"\n",
    "\n",
    "image_shape, feature_vector, sampling_index, memory_reduce, threshold = tfdet.dataset.util.load_pickle(save_path)\n",
    "    \n",
    "with device:\n",
    "    x = tf.keras.layers.Input(shape = [*image_shape, 3])\n",
    "    out = tfdet.model.backbone.wide_resnet50_2(x, weights = \"imagenet_v2\", indices = [0, 1, 2])\n",
    "    score, mask = tfdet.model.detector.padim(out, feature_vector, image_shape = image_shape, sampling_index = sampling_index, memory_reduce = memory_reduce) #align memory_reduce with train in test\n",
    "    filtered_out = tfdet.model.postprocess.padim.FilterDetection(threshold = threshold)([score, mask])\n",
    "    model = tf.keras.Model(x, filtered_out)\n",
    "    \n",
    "score_pred, mask_pred = model.predict(te_pipe, verbose = 0)\n",
    "print(\"score : {0:.4f}\".format(np.mean((0 < score_pred) == te_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daecc2e",
   "metadata": {},
   "source": [
    "# 6. Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcf6f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "index = 0\n",
    "x_true = te_dataset[index] #or next(iter(tr_dataset))\n",
    "y_true = te_y[index]\n",
    "\n",
    "score_pred, mask_pred = model.predict(np.expand_dims(x_true, axis = 0), verbose = 0)\n",
    "\n",
    "x_true = tfdet.dataset.transform.unnormalize(x_true, mean = [123.675, 116.28, 103.53], std = [58.395, 57.12, 57.375])\n",
    "\n",
    "print(y_true, score_pred[0])\n",
    "fig_size = (5, 5)\n",
    "plt.figure(figsize = fig_size)\n",
    "plt.imshow(x_true)\n",
    "plt.figure(figsize = fig_size)\n",
    "plt.imshow(mask_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c381358",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
