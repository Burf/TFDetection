{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "463465c1",
   "metadata": {},
   "source": [
    "# 0. Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffe8540c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./tfdet\"):\n",
    "    !git clone -q http://github.com/burf/tfdetection.git\n",
    "    !mv ./tfdetection/tfdet ./tfdet\n",
    "    !rm -rf ./tfdetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27301d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore warning\n",
    "import warnings, os\n",
    "warnings.filterwarnings(action = \"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "import tfdet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdda77b5",
   "metadata": {},
   "source": [
    "# 1. Init Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "593b8cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample dataset\n",
    "import functools\n",
    "import numpy as np\n",
    "\n",
    "image_shape = [512, 512]\n",
    "n_class = 21 #background + 20 label\n",
    "max_pad_size = 100\n",
    "total_data_size = 4\n",
    "batch_size = 1\n",
    "\n",
    "def load(mask = False):\n",
    "    image = np.random.random([*image_shape, 3]).astype(np.float32)\n",
    "    y_true = np.random.randint(n_class, size = [max_pad_size, 1])\n",
    "    bbox_true = np.array([tfdet.core.bbox.random_bbox(image_shape = image_shape) for _ in range(max_pad_size)])\n",
    "    result = [image, y_true, bbox_true]\n",
    "    if mask:\n",
    "        mask_true = np.random.random((max_pad_size, *image_shape, 1)).astype(np.float32)\n",
    "        result = [image, y_true, bbox_true, mask_true]\n",
    "    return tuple(result)\n",
    "\n",
    "def generator(mask = False):\n",
    "    for _ in range(total_data_size):\n",
    "        yield load(mask = mask)\n",
    "        \n",
    "mask_genrator = functools.partial(generator, mask = True)\n",
    "bbox_pipe = tf.data.Dataset.from_generator(generator, (tf.float32, tf.int32, tf.int32))\n",
    "mask_pipe = tf.data.Dataset.from_generator(mask_genrator, (tf.float32, tf.int32, tf.int32, tf.float32))\n",
    "\n",
    "bbox_pipe = tfdet.dataset.pipeline.args2dict(bbox_pipe).batch(batch_size)\n",
    "mask_pipe = tfdet.dataset.pipeline.args2dict(mask_pipe).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82178953",
   "metadata": {},
   "source": [
    "# 2. Build 1-Stage Object Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f52a32c",
   "metadata": {},
   "source": [
    "2-1. RetinaNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e5ced1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 10s 2s/step - loss: 10604296.0000 - score_accuracy: 0.0000e+00 - score_loss: 10604296.0000 - regress_loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(4, 100, 21), (4, 100, 4)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "x = tf.keras.layers.Input(shape = [*image_shape, 3], name = \"x_true\")\n",
    "feature = tfdet.model.backbone.resnet50(x, weights = \"imagenet\")\n",
    "\n",
    "out = tfdet.model.detector.retinanet(feature, image_shape = tf.shape(x)[1:3], n_class = n_class, scale = [32, 64, 128, 256, 512], ratio = [0.5, 1, 2], octave = 3)\n",
    "\n",
    "model = tfdet.model.train.retina.train_model(x, *out,\n",
    "                                             proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)\n",
    "model.compile()\n",
    "model.evaluate(bbox_pipe)\n",
    "[p.shape for p in model.predict(bbox_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ad33ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 100, 21), (4, 100, 4)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict model\n",
    "nms_out = tfdet.model.postprocess.retina.FilterDetection(proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)(out)\n",
    "model = tf.keras.Model(x, nms_out)\n",
    "[p.shape for p in model.predict(bbox_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ee2fc2",
   "metadata": {},
   "source": [
    "2-2. EfficientDet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64cf4632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 12s 660ms/step - loss: 189529.8125 - score_accuracy: 0.0000e+00 - score_loss: 189529.8125 - regress_loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(4, 100, 21), (4, 100, 4)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "x = tf.keras.layers.Input(shape = [*image_shape, 3], name = \"x_true\")\n",
    "out = tfdet.model.detector.effdet_d4(x, n_class = n_class, scale = [32, 64, 128, 256, 512], ratio = [0.5, 1, 2], octave = 3, weights = \"imagenet\")\n",
    "\n",
    "model = tfdet.model.train.effdet.train_model(x, *out,\n",
    "                                             proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)\n",
    "model.compile()\n",
    "model.evaluate(bbox_pipe)\n",
    "[p.shape for p in model.predict(bbox_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f624d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 100, 21), (4, 100, 4)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict model\n",
    "nms_out = tfdet.model.postprocess.effdet.FilterDetection(proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)(out)\n",
    "model = tf.keras.Model(x, nms_out)\n",
    "[p.shape for p in model.predict(bbox_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4151422",
   "metadata": {},
   "source": [
    "2-3. EfficientDet-Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa0f1bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 7s 478ms/step - loss: 189529.8125 - score_accuracy: 0.0000e+00 - score_loss: 189529.8125 - regress_loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(4, 100, 21), (4, 100, 4)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "x = tf.keras.layers.Input(shape = [*image_shape, 3], name = \"x_true\")\n",
    "out = tfdet.model.detector.effdet_lite_d4(x, n_class = n_class, scale = [32, 64, 128, 256, 512], ratio = [0.5, 1, 2], octave = 3, weights = \"imagenet\")\n",
    "\n",
    "model = tfdet.model.train.effdet.train_model(x, *out,\n",
    "                                             proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)\n",
    "model.compile()\n",
    "model.evaluate(bbox_pipe)\n",
    "[p.shape for p in model.predict(bbox_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2005828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 100, 21), (4, 100, 4)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict model\n",
    "nms_out = tfdet.model.postprocess.effdet.FilterDetection(proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)(out)\n",
    "model = tf.keras.Model(x, nms_out)\n",
    "[p.shape for p in model.predict(bbox_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510c4f25",
   "metadata": {},
   "source": [
    "2-4. Yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88e76575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 6s 770ms/step - loss: 2097.4285 - score_accuracy: 0.2500 - logits_accuracy: 0.2500 - score_loss: 2096.2441 - logits_loss: 0.9343 - regress_loss: 0.2500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(4, 100, 21), (4, 100, 4)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "x = tf.keras.layers.Input(shape = [*image_shape, 3], name = \"x_true\")\n",
    "out = tfdet.model.detector.yolo_v4(x, n_class = n_class, size = [[ 10, 13], [ 16,  30], [ 33,  23], \n",
    "                                                                 [ 30, 61], [ 62,  45], [ 59, 119], \n",
    "                                                                 [116, 90], [156, 198], [373, 326]], weights = \"darknet\")\n",
    "\n",
    "model = tfdet.model.train.yolo.train_model(x, *out,\n",
    "                                           proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)\n",
    "model.compile()\n",
    "model.evaluate(bbox_pipe)\n",
    "[p.shape for p in model.predict(bbox_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52d7aaa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 100, 21), (4, 100, 4)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict model\n",
    "nms_out = tfdet.model.postprocess.yolo.FilterDetection(proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)(out)\n",
    "model = tf.keras.Model(x, nms_out)\n",
    "[p.shape for p in model.predict(bbox_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6460d19",
   "metadata": {},
   "source": [
    "## 3. Build 2-Stage Object Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e279aa51",
   "metadata": {},
   "source": [
    "3-1. Faster R-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cece2a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 7s 708ms/step - loss: 7255983104.0000 - rpn_score_accuracy: 0.0000e+00 - cls_logits_accuracy: 0.0000e+00 - rpn_score_loss: 0.0000e+00 - rpn_regress_loss: 0.0000e+00 - cls_logits_loss: 10.6529 - cls_regress_loss: 7255983104.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(4, 100, 21), (4, 100, 4)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "x = tf.keras.layers.Input(shape = [*image_shape, 3], name = \"x_true\")\n",
    "feature = tfdet.model.backbone.resnet50(x, weights = \"imagenet\")\n",
    "\n",
    "out = tfdet.model.detector.faster_rcnn(feature, image_shape = tf.shape(x)[1:3], n_class = n_class, scale = [32, 64, 128, 256, 512], ratio = [0.5, 1, 2], proposal_count = 2000,\n",
    "                                       sampling_count = 256, sampling_positive_ratio = 0.25) #sampling for train\n",
    "\n",
    "model = tfdet.model.train.rcnn.train_model(x, *out, rpn_positive_ratio = 0.5,\n",
    "                                           proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)\n",
    "model.compile()\n",
    "model.evaluate(bbox_pipe)\n",
    "[p.shape for p in model.predict(bbox_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7771160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 100, 21), (4, 100, 4)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict model\n",
    "x = tf.keras.layers.Input(shape = [*image_shape, 3], name = \"x_true\")\n",
    "feature = tfdet.model.backbone.resnet50(x, weights = \"imagenet\")\n",
    "\n",
    "out = tfdet.model.detector.faster_rcnn(feature, image_shape = tf.shape(x)[1:3], n_class = n_class, scale = [32, 64, 128, 256, 512], ratio = [0.5, 1, 2], proposal_count = 1000)\n",
    "nms_out = tfdet.model.postprocess.rcnn.FilterDetection(proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)(out)\n",
    "model = tf.keras.Model(x, nms_out)\n",
    "[p.shape for p in model.predict(bbox_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de0e5f2",
   "metadata": {},
   "source": [
    "3-2. Mask R-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29ceef9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 9s 1s/step - loss: 1.0797e-05 - rpn_score_accuracy: 0.0000e+00 - cls_logits_accuracy: 0.0000e+00 - rpn_score_loss: 0.0000e+00 - rpn_regress_loss: 0.0000e+00 - cls_logits_loss: 0.0000e+00 - cls_regress_loss: 0.0000e+00 - cls_mask_loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(4, 100, 21), (4, 100, 4), (4, 100, 14, 14, 1)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "x = tf.keras.layers.Input(shape = [*image_shape, 3], name = \"x_true\")\n",
    "feature = tfdet.model.backbone.resnet50(x, weights = \"imagenet\")\n",
    "\n",
    "out = tfdet.model.detector.mask_rcnn(feature, image_shape = tf.shape(x)[1:3], n_class = n_class, scale = [32, 64, 128, 256, 512], ratio = [0.5, 1, 2], proposal_count = 2000,\n",
    "                                     sampling_count = 256, sampling_positive_ratio = 0.25) #sampling for train\n",
    "\n",
    "model = tfdet.model.train.rcnn.train_model(x, *out, rpn_positive_ratio = 0.5,\n",
    "                                           proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)\n",
    "model.compile()\n",
    "model.evaluate(mask_pipe)\n",
    "[p.shape for p in model.predict(mask_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "970312ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 100, 21), (4, 100, 4), (4, 100, 14, 14, 1)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict model\n",
    "x = tf.keras.layers.Input(shape = [*image_shape, 3], name = \"x_true\")\n",
    "feature = tfdet.model.backbone.resnet50(x, weights = \"imagenet\")\n",
    "\n",
    "out = tfdet.model.detector.mask_rcnn(feature, image_shape = tf.shape(x)[1:3], n_class = n_class, scale = [32, 64, 128, 256, 512], ratio = [0.5, 1, 2], proposal_count = 1000)\n",
    "nms_out = tfdet.model.postprocess.rcnn.FilterDetection(proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)(out)\n",
    "model = tf.keras.Model(x, nms_out)\n",
    "[p.shape for p in model.predict(mask_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b2922c",
   "metadata": {},
   "source": [
    "3-3. Cascade R-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e7cc13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 10s 757ms/step - loss: 48816566272.0000 - rpn_score_accuracy: 0.0000e+00 - cls_logits_accuracy1: 0.0012 - cls_logits_accuracy2: 0.0000e+00 - cls_logits_accuracy3: 0.0179 - rpn_score_loss: 0.0000e+00 - rpn_regress_loss: 0.0000e+00 - cls_logits_loss1: 22.3307 - cls_regress_loss1: 18266603520.0000 - cls_logits_loss2: 10.7794 - cls_regress_loss2: 17456906240.0000 - cls_logits_loss3: 4.3888 - cls_regress_loss3: 13093052416.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(4, 100, 21), (4, 100, 4)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "x = tf.keras.layers.Input(shape = [*image_shape, 3], name = \"x_true\")\n",
    "feature = tfdet.model.backbone.resnet50(x, weights = \"imagenet\")\n",
    "\n",
    "out = tfdet.model.detector.cascade_rcnn(feature, image_shape = tf.shape(x)[1:3], n_class = n_class, scale = [32, 64, 128, 256, 512], ratio = [0.5, 1, 2], proposal_count = 2000,\n",
    "                                        sampling_count = 256, sampling_positive_ratio = 0.25) #sampling for train\n",
    "\n",
    "model = tfdet.model.train.rcnn.train_model(x, *out, rpn_positive_ratio = 0.5,\n",
    "                                           proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)\n",
    "model.compile()\n",
    "model.evaluate(bbox_pipe)\n",
    "[p.shape for p in model.predict(bbox_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6623cbb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 100, 21), (4, 100, 4)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict model\n",
    "x = tf.keras.layers.Input(shape = [*image_shape, 3], name = \"x_true\")\n",
    "feature = tfdet.model.backbone.resnet50(x, weights = \"imagenet\")\n",
    "\n",
    "out = tfdet.model.detector.cascade_rcnn(feature, image_shape = tf.shape(x)[1:3], n_class = n_class, scale = [32, 64, 128, 256, 512], ratio = [0.5, 1, 2], proposal_count = 1000)\n",
    "nms_out = tfdet.model.postprocess.rcnn.FilterDetection(proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)(out)\n",
    "model = tf.keras.Model(x, nms_out)\n",
    "[p.shape for p in model.predict(bbox_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d0d59d",
   "metadata": {},
   "source": [
    "3-4. Hybrid Task Cascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e529cd69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 19s 2s/step - loss: 27644508160.0000 - rpn_score_accuracy: 0.0000e+00 - cls_logits_accuracy1: 0.0000e+00 - cls_logits_accuracy2: 0.0000e+00 - cls_logits_accuracy3: 0.0301 - rpn_score_loss: 0.0000e+00 - rpn_regress_loss: 0.0000e+00 - cls_logits_loss1: 16.1181 - cls_regress_loss1: 9993922560.0000 - cls_mask_loss1: 0.4699 - cls_logits_loss2: 7.9956 - cls_regress_loss2: 9965840384.0000 - cls_mask_loss2: 0.2340 - cls_logits_loss3: 1.4308 - cls_regress_loss3: 7684745216.0000 - cls_mask_loss3: 0.0684 - semantic_loss: 31.3341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(4, 100, 21), (4, 100, 4), (4, 100, 14, 14, 1)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "x = tf.keras.layers.Input(shape = [*image_shape, 3], name = \"x_true\")\n",
    "feature = tfdet.model.backbone.resnet50(x, weights = \"imagenet\")\n",
    "\n",
    "out = tfdet.model.detector.hybrid_task_cascade(feature, image_shape = tf.shape(x)[1:3], n_class = n_class, scale = [32, 64, 128, 256, 512], ratio = [0.5, 1, 2], proposal_count = 2000,\n",
    "                                               sampling_count = 256, sampling_positive_ratio = 0.25) #sampling for train\n",
    "\n",
    "model = tfdet.model.train.rcnn.train_model(x, *out, rpn_positive_ratio = 0.5,\n",
    "                                           proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)\n",
    "model.compile()\n",
    "model.evaluate(mask_pipe)\n",
    "[p.shape for p in model.predict(mask_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4cefd0a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 100, 21), (4, 100, 4), (4, 100, 14, 14, 1)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict model\n",
    "x = tf.keras.layers.Input(shape = [*image_shape, 3], name = \"x_true\")\n",
    "feature = tfdet.model.backbone.resnet50(x, weights = \"imagenet\")\n",
    "\n",
    "out = tfdet.model.detector.hybrid_task_cascade(feature, image_shape = tf.shape(x)[1:3], n_class = n_class, scale = [32, 64, 128, 256, 512], ratio = [0.5, 1, 2], proposal_count = 1000)\n",
    "nms_out = tfdet.model.postprocess.rcnn.FilterDetection(proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)(out)\n",
    "model = tf.keras.Model(x, nms_out)\n",
    "[p.shape for p in model.predict(mask_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e650fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
