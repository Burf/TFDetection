{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1d41102",
   "metadata": {},
   "source": [
    "# 0. Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5282570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./tfdet\"):\n",
    "    !git clone -q http://github.com/burf/tfdetection.git\n",
    "    !mv ./tfdetection/tfdet ./tfdet\n",
    "    !rm -rf ./tfdetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a30d0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore warning\n",
    "import warnings, os\n",
    "warnings.filterwarnings(action = \"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "import tfdet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96890c14",
   "metadata": {},
   "source": [
    "# 1. Init Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "715aa6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample dataset\n",
    "import numpy as np\n",
    "\n",
    "#image_shape = [512, 512]\n",
    "image_shape = [256, 256]\n",
    "n_class = 21 #background + 20 label\n",
    "batch_size = 16\n",
    "\n",
    "def load(x_true, mask = True):\n",
    "    max_pad_size = np.random.randint(10) + 1\n",
    "    \n",
    "    image = np.random.random([*image_shape, 3]).astype(np.float32)\n",
    "    y_true = np.random.randint(n_class, size = [max_pad_size, 1]).astype(np.int32)\n",
    "    bbox_true = np.array([tfdet.core.bbox.random_bbox(image_shape = image_shape) for _ in range(max_pad_size)], dtype = np.int32)\n",
    "    result = [image, y_true, bbox_true]\n",
    "    if mask:\n",
    "        mask_true = np.random.randint(2, size = (max_pad_size, *image_shape, 1)).astype(np.uint8)\n",
    "        result = [image, y_true, bbox_true, mask_true]\n",
    "    return tuple(result)\n",
    "\n",
    "bbox_dataset = tfdet.dataset.Dataset(np.arange(10), transform = [{\"name\":load, \"mask\":False}, #or load,\n",
    "                                                                 {\"name\":\"resize\", \"image_shape\":image_shape},\n",
    "                                                                 {\"name\":\"pad\", \"image_shape\":image_shape},\n",
    "                                                                 {\"name\":\"filter_annotation\"},\n",
    "                                                                 #{\"name\":\"label_encode\", \"label\":None},\n",
    "                                                                 {\"name\":\"normalize\", \"mean\":[123.675, 116.28, 103.53], \"std\":[58.395, 57.12, 57.375]}])\n",
    "\n",
    "mask_dataset = tfdet.dataset.Dataset(np.arange(10), transform = [{\"name\":load, \"mask\":True}, #or load,\n",
    "                                                                 {\"name\":\"resize\", \"image_shape\":image_shape},\n",
    "                                                                 {\"name\":\"pad\", \"image_shape\":image_shape},\n",
    "                                                                 {\"name\":\"filter_annotation\"},\n",
    "                                                                 #{\"name\":\"label_encode\", \"label\":None},\n",
    "                                                                 {\"name\":\"normalize\", \"mean\":[123.675, 116.28, 103.53], \"std\":[58.395, 57.12, 57.375]},\n",
    "                                                                 {\"name\":\"mask_downscale\", \"scale\":8}])\n",
    "\n",
    "bbox_pipe = tfdet.dataset.PipeLoader(bbox_dataset)\n",
    "bbox_pipe = tfdet.dataset.pipeline.args2dict(bbox_pipe, batch_size = batch_size, prefetch = True)\n",
    "\n",
    "mask_pipe = tfdet.dataset.PipeLoader(mask_dataset)\n",
    "mask_pipe = tfdet.dataset.pipeline.args2dict(mask_pipe, batch_size = batch_size, prefetch = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9395f824",
   "metadata": {},
   "source": [
    "# 2. Build 1-Stage Object Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fecf91",
   "metadata": {},
   "source": [
    "2-1. RetinaNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b51fba54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step - loss: 5688.9619 - loss_class: 5678.9521 - loss_bbox: 10.0098\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(10, 100, 21), (10, 100, 4)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "x = tf.keras.layers.Input(shape = [*image_shape, 3], name = \"x_true\")\n",
    "feature = tfdet.model.backbone.resnet50(x, frozen_stages = 1, weights = \"imagenet_v2\")\n",
    "\n",
    "out = tfdet.model.detector.retinanet(feature, image_shape = tf.shape(x)[1:3], n_class = n_class, scale = [32, 64, 128, 256, 512], ratio = [0.5, 1, 2], octave = 3)\n",
    "\n",
    "model = tfdet.model.train.retina.train_model(x, *out,\n",
    "                                             proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)\n",
    "model.compile()\n",
    "model.evaluate(bbox_pipe)\n",
    "[p.shape for p in model.predict(bbox_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d74fd2fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 100, 21), (10, 100, 4)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict model\n",
    "nms_out = tfdet.model.postprocess.retina.FilterDetection(proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)(out)\n",
    "model = tf.keras.Model(x, nms_out)\n",
    "[p.shape for p in model.predict(bbox_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe638137",
   "metadata": {},
   "source": [
    "2-2. EfficientDet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "817526ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 9s 9s/step - loss: 2017.4082 - loss_class: 2014.9301 - loss_bbox: 2.4767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(10, 100, 21), (10, 100, 4)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "x = tf.keras.layers.Input(shape = [*image_shape, 3], name = \"x_true\")\n",
    "out = tfdet.model.detector.effdet_d4(x, n_class = n_class, scale = [32, 64, 128, 256, 512], ratio = [0.5, 1, 2], octave = 3, weights = \"imagenet\")\n",
    "\n",
    "model = tfdet.model.train.effdet.train_model(x, *out,\n",
    "                                             proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)\n",
    "model.compile()\n",
    "model.evaluate(bbox_pipe)\n",
    "[p.shape for p in model.predict(bbox_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fb60f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 100, 21), (10, 100, 4)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict model\n",
    "nms_out = tfdet.model.postprocess.effdet.FilterDetection(proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)(out)\n",
    "model = tf.keras.Model(x, nms_out)\n",
    "[p.shape for p in model.predict(bbox_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b8c57d",
   "metadata": {},
   "source": [
    "2-3. EfficientDet-Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a839cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 6s 6s/step - loss: 4320.0464 - loss_class: 4317.6992 - loss_bbox: 2.3471\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(10, 100, 21), (10, 100, 4)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "x = tf.keras.layers.Input(shape = [*image_shape, 3], name = \"x_true\")\n",
    "out = tfdet.model.detector.effdet_lite_d4(x, n_class = n_class, scale = [32, 64, 128, 256, 512], ratio = [0.5, 1, 2], octave = 3, weights = \"imagenet\")\n",
    "\n",
    "model = tfdet.model.train.effdet.train_model(x, *out,\n",
    "                                             proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)\n",
    "model.compile()\n",
    "model.evaluate(bbox_pipe)\n",
    "[p.shape for p in model.predict(bbox_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a75c5707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 100, 21), (10, 100, 4)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict model\n",
    "nms_out = tfdet.model.postprocess.effdet.FilterDetection(proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)(out)\n",
    "model = tf.keras.Model(x, nms_out)\n",
    "[p.shape for p in model.predict(bbox_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c18ad16",
   "metadata": {},
   "source": [
    "2-4. Yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b0df381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step - loss: 302.2051 - loss_score: 291.7308 - loss_class: 7.7077 - loss_bbox: 2.7667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(10, 100, 21), (10, 100, 4)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "x = tf.keras.layers.Input(shape = [*image_shape, 3], name = \"x_true\")\n",
    "out = tfdet.model.detector.yolo_v4(x, n_class = n_class, size = [[ 10, 13], [ 16,  30], [ 33,  23], \n",
    "                                                                 [ 30, 61], [ 62,  45], [ 59, 119], \n",
    "                                                                 [116, 90], [156, 198], [373, 326]], weights = \"darknet\")\n",
    "\n",
    "model = tfdet.model.train.yolo.train_model(x, *out,\n",
    "                                           proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)\n",
    "model.compile()\n",
    "model.evaluate(bbox_pipe)\n",
    "[p.shape for p in model.predict(bbox_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92d756b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 100, 21), (10, 100, 4)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict model\n",
    "nms_out = tfdet.model.postprocess.yolo.FilterDetection(proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)(out)\n",
    "model = tf.keras.Model(x, nms_out)\n",
    "[p.shape for p in model.predict(bbox_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc82f6a4",
   "metadata": {},
   "source": [
    "2-5. FCOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d9e2e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 6s 6s/step - loss: 14739.4541 - loss_class: 14732.3281 - loss_bbox: 4.7866 - loss_conf: 2.3385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(10, 100, 21), (10, 100, 4)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "x = tf.keras.layers.Input(shape = [*image_shape, 3], name = \"x_true\")\n",
    "feature = tfdet.model.backbone.resnet50(x, frozen_stages = 1, weights = \"imagenet_v2\")\n",
    "\n",
    "out = tfdet.model.detector.fcos(feature, image_shape = tf.shape(x)[1:3], n_class = n_class)\n",
    "\n",
    "model = tfdet.model.train.fcos.train_model(x, *out,\n",
    "                                           proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)\n",
    "model.compile()\n",
    "model.evaluate(bbox_pipe)\n",
    "[p.shape for p in model.predict(bbox_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3110ed92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 100, 21), (10, 100, 4)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict model\n",
    "nms_out = tfdet.model.postprocess.fcos.FilterDetection(proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)(out)\n",
    "model = tf.keras.Model(x, nms_out)\n",
    "[p.shape for p in model.predict(bbox_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55eb50fe",
   "metadata": {},
   "source": [
    "## 3. Build 2-Stage Object Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a806d4",
   "metadata": {},
   "source": [
    "3-1. Faster R-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "371b9472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step - loss: 5518.9307 - loss_rpn_class: 3061.1157 - loss_rpn_bbox: 2.6287 - loss_roi_class: 2453.4419 - loss_roi_bbox: 1.7446\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(10, 100, 21), (10, 100, 4)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "x = tf.keras.layers.Input(shape = [*image_shape, 3], name = \"x_true\")\n",
    "feature = tfdet.model.backbone.resnet50(x, frozen_stages = 1, weights = \"imagenet_v2\")\n",
    "\n",
    "out = tfdet.model.detector.faster_rcnn(feature, image_shape = tf.shape(x)[1:3], n_class = n_class, scale = [32, 64, 128, 256, 512], ratio = [0.5, 1, 2],\n",
    "                                       train = True)\n",
    "\n",
    "model = tfdet.model.train.rcnn.train_model(x, *out,\n",
    "                                           proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)\n",
    "model.compile()\n",
    "model.evaluate(bbox_pipe)\n",
    "[p.shape for p in model.predict(bbox_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2401cabf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 100, 21), (10, 100, 4)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict model\n",
    "x = tf.keras.layers.Input(shape = [*image_shape, 3], name = \"x_true\")\n",
    "feature = tfdet.model.backbone.resnet50(x, frozen_stages = 1, weights = \"imagenet_v2\")\n",
    "\n",
    "out = tfdet.model.detector.faster_rcnn(feature, image_shape = tf.shape(x)[1:3], n_class = n_class, scale = [32, 64, 128, 256, 512], ratio = [0.5, 1, 2])\n",
    "nms_out = tfdet.model.postprocess.rcnn.FilterDetection(proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)(out)\n",
    "model = tf.keras.Model(x, nms_out)\n",
    "[p.shape for p in model.predict(bbox_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370df8b8",
   "metadata": {},
   "source": [
    "3-2. Mask R-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a092eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 10s 10s/step - loss: 7354.8213 - loss_rpn_class: 4646.4443 - loss_rpn_bbox: 2.3232 - loss_roi_class: 2704.1577 - loss_roi_bbox: 1.1872 - loss_roi_mask: 0.7090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(10, 100, 21), (10, 100, 4), (10, 100, 14, 14, 1)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "x = tf.keras.layers.Input(shape = [*image_shape, 3], name = \"x_true\")\n",
    "feature = tfdet.model.backbone.resnet50(x, frozen_stages = 1, weights = \"imagenet_v2\")\n",
    "\n",
    "out = tfdet.model.detector.mask_rcnn(feature, image_shape = tf.shape(x)[1:3], n_class = n_class, scale = [32, 64, 128, 256, 512], ratio = [0.5, 1, 2],\n",
    "                                     train = True, mask_pool_size = 7)\n",
    "\n",
    "model = tfdet.model.train.rcnn.train_model(x, *out,\n",
    "                                           proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)\n",
    "model.compile()\n",
    "model.evaluate(mask_pipe)\n",
    "[p.shape for p in model.predict(mask_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b28bbd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 100, 21), (10, 100, 4), (10, 100, 14, 14, 1)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict model\n",
    "x = tf.keras.layers.Input(shape = [*image_shape, 3], name = \"x_true\")\n",
    "feature = tfdet.model.backbone.resnet50(x, frozen_stages = 1, weights = \"imagenet_v2\")\n",
    "\n",
    "out = tfdet.model.detector.mask_rcnn(feature, image_shape = tf.shape(x)[1:3], n_class = n_class, scale = [32, 64, 128, 256, 512], ratio = [0.5, 1, 2], \n",
    "                                     mask_pool_size = 7)\n",
    "nms_out = tfdet.model.postprocess.rcnn.FilterDetection(proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)(out)\n",
    "model = tf.keras.Model(x, nms_out)\n",
    "[p.shape for p in model.predict(mask_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2a6a44",
   "metadata": {},
   "source": [
    "3-3. Cascade R-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c638d316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 7s 7s/step - loss: 8873.5205 - loss_rpn_class: 3283.8320 - loss_rpn_bbox: 1.6162 - loss_roi_class_1: 3511.5962 - loss_roi_bbox_1: 0.0000e+00 - loss_roi_class_2: 1289.3551 - loss_roi_bbox_2: 0.0000e+00 - loss_roi_class_3: 787.1217 - loss_roi_bbox_3: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(10, 100, 21), (10, 100, 4)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "x = tf.keras.layers.Input(shape = [*image_shape, 3], name = \"x_true\")\n",
    "feature = tfdet.model.backbone.resnet50(x, frozen_stages = 1, weights = \"imagenet_v2\")\n",
    "\n",
    "out = tfdet.model.detector.cascade_rcnn(feature, image_shape = tf.shape(x)[1:3], n_class = n_class, scale = [32, 64, 128, 256, 512], ratio = [0.5, 1, 2],\n",
    "                                        train = True)\n",
    "\n",
    "model = tfdet.model.train.rcnn.train_model(x, *out,\n",
    "                                           proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)\n",
    "model.compile()\n",
    "model.evaluate(bbox_pipe)\n",
    "[p.shape for p in model.predict(bbox_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b0b7a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 100, 21), (10, 100, 4)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict model\n",
    "x = tf.keras.layers.Input(shape = [*image_shape, 3], name = \"x_true\")\n",
    "feature = tfdet.model.backbone.resnet50(x, frozen_stages = 1, weights = \"imagenet_v2\")\n",
    "\n",
    "out = tfdet.model.detector.cascade_rcnn(feature, image_shape = tf.shape(x)[1:3], n_class = n_class, scale = [32, 64, 128, 256, 512], ratio = [0.5, 1, 2])\n",
    "nms_out = tfdet.model.postprocess.rcnn.FilterDetection(proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)(out)\n",
    "model = tf.keras.Model(x, nms_out)\n",
    "[p.shape for p in model.predict(bbox_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206c7b0b",
   "metadata": {},
   "source": [
    "3-4. Hybrid Task Cascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e3e0120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 29s 29s/step - loss: 5615.0259 - loss_rpn_class: 1407.0381 - loss_rpn_bbox: 2.8818 - loss_roi_class_1: 1600.0781 - loss_roi_bbox_1: 2.9274 - loss_roi_mask_1: 1.3057 - loss_roi_class_2: 2140.2781 - loss_roi_bbox_2: 0.8526 - loss_roi_mask_2: 0.1734 - loss_roi_class_3: 456.9531 - loss_roi_bbox_3: 0.0000e+00 - loss_roi_mask_3: 0.0000e+00 - loss_semantic: 2.5374\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(10, 100, 21), (10, 100, 4), (10, 100, 14, 14, 1)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "x = tf.keras.layers.Input(shape = [*image_shape, 3], name = \"x_true\")\n",
    "feature = tfdet.model.backbone.resnet50(x, frozen_stages = 1, weights = \"imagenet_v2\")\n",
    "\n",
    "out = tfdet.model.detector.hybrid_task_cascade(feature, image_shape = tf.shape(x)[1:3], n_class = n_class, scale = [32, 64, 128, 256, 512], ratio = [0.5, 1, 2],\n",
    "                                               train = True, mask_pool_size = 7)\n",
    "\n",
    "model = tfdet.model.train.rcnn.train_model(x, *out,\n",
    "                                           proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)\n",
    "model.compile()\n",
    "model.evaluate(mask_pipe)\n",
    "[p.shape for p in model.predict(mask_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef8c37dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 100, 21), (10, 100, 4), (10, 100, 14, 14, 1)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict model\n",
    "x = tf.keras.layers.Input(shape = [*image_shape, 3], name = \"x_true\")\n",
    "feature = tfdet.model.backbone.resnet50(x, frozen_stages = 1, weights = \"imagenet_v2\")\n",
    "\n",
    "out = tfdet.model.detector.hybrid_task_cascade(feature, image_shape = tf.shape(x)[1:3], n_class = n_class, scale = [32, 64, 128, 256, 512], ratio = [0.5, 1, 2], \n",
    "                                               mask_pool_size = 7)\n",
    "nms_out = tfdet.model.postprocess.rcnn.FilterDetection(proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)(out)\n",
    "model = tf.keras.Model(x, nms_out)\n",
    "[p.shape for p in model.predict(mask_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9317ab15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
