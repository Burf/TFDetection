{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9b84f23",
   "metadata": {},
   "source": [
    "# 0. Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2263c015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./tfdet\"):\n",
    "    !git clone -q http://github.com/burf/tfdetection.git\n",
    "    !mv ./tfdetection/tfdet ./tfdet\n",
    "    !rm -rf ./tfdetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42a46c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore warning\n",
    "import warnings, os\n",
    "warnings.filterwarnings(action = \"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "import tfdet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6da35b",
   "metadata": {},
   "source": [
    "# 1. Init Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a993654b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample dataset\n",
    "import numpy as np\n",
    "\n",
    "#image_shape = [512, 512]\n",
    "image_shape = [256, 256]\n",
    "n_class = 21 #background + 20 label\n",
    "batch_size = 16\n",
    "\n",
    "def load(x_true, mask = True):\n",
    "    max_pad_size = np.random.randint(10) + 1\n",
    "    \n",
    "    image = np.random.random([*image_shape, 3]).astype(np.float32)\n",
    "    y_true = np.random.randint(n_class, size = [max_pad_size, 1]).astype(np.int32)\n",
    "    bbox_true = np.array([tfdet.core.bbox.random_bbox(image_shape = image_shape) for _ in range(max_pad_size)], dtype = np.int32)\n",
    "    result = [image, y_true, bbox_true]\n",
    "    if mask:\n",
    "        mask_true = np.random.randint(2, size = (max_pad_size, *image_shape, 1)).astype(np.uint8)\n",
    "        result = [image, y_true, bbox_true, mask_true]\n",
    "    return tuple(result)\n",
    "\n",
    "bbox_dataset = tfdet.dataset.Dataset(np.arange(10), transform = [{\"name\":load, \"mask\":False}, #or load,\n",
    "                                                                 {\"name\":\"resize\", \"image_shape\":image_shape},\n",
    "                                                                 {\"name\":\"pad\", \"image_shape\":image_shape},\n",
    "                                                                 {\"name\":\"filter_annotation\"},\n",
    "                                                                 #{\"name\":\"label_encode\", \"label\":None},\n",
    "                                                                 {\"name\":\"normalize\", \"mean\":[123.675, 116.28, 103.53], \"std\":[58.395, 57.12, 57.375]}])\n",
    "\n",
    "mask_dataset = tfdet.dataset.Dataset(np.arange(10), transform = [{\"name\":load, \"mask\":True}, #or load,\n",
    "                                                                 {\"name\":\"resize\", \"image_shape\":image_shape},\n",
    "                                                                 {\"name\":\"pad\", \"image_shape\":image_shape},\n",
    "                                                                 {\"name\":\"filter_annotation\"},\n",
    "                                                                 #{\"name\":\"label_encode\", \"label\":None},\n",
    "                                                                 {\"name\":\"normalize\", \"mean\":[123.675, 116.28, 103.53], \"std\":[58.395, 57.12, 57.375]},\n",
    "                                                                 {\"name\":\"mask_downscale\", \"scale\":8}])\n",
    "\n",
    "bbox_pipe = tfdet.dataset.PipeLoader(bbox_dataset)\n",
    "bbox_pipe = tfdet.dataset.pipeline.args2dict(bbox_pipe, batch_size = batch_size, prefetch = True)\n",
    "\n",
    "mask_pipe = tfdet.dataset.PipeLoader(mask_dataset)\n",
    "mask_pipe = tfdet.dataset.pipeline.args2dict(mask_pipe, batch_size = batch_size, prefetch = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdd4187",
   "metadata": {},
   "source": [
    "# 2. Build 1-Stage Object Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f043d092",
   "metadata": {},
   "source": [
    "2-1. RetinaNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4432d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step - loss: 4953.3340 - loss_class: 4941.7388 - loss_bbox: 11.5954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(10, 100, 21), (10, 100, 4)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "x = tf.keras.layers.Input(shape = [*image_shape, 3], name = \"x_true\")\n",
    "feature = tfdet.model.backbone.resnet50(x, frozen_stages = 1, weights = \"imagenet_v2\")\n",
    "\n",
    "out = tfdet.model.detector.retinanet(feature, image_shape = tf.shape(x)[1:3], n_class = n_class, scale = [32, 64, 128, 256, 512], ratio = [0.5, 1, 2], octave = 3)\n",
    "\n",
    "model = tfdet.model.train.retina.train_model(x, *out,\n",
    "                                             proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)\n",
    "model.compile()\n",
    "model.evaluate(bbox_pipe)\n",
    "[p.shape for p in model.predict(bbox_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "030cd49b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 100, 21), (10, 100, 4)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict model\n",
    "nms_out = tfdet.model.postprocess.retina.FilterDetection(proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)(out)\n",
    "model = tf.keras.Model(x, nms_out)\n",
    "[p.shape for p in model.predict(bbox_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301fc39f",
   "metadata": {},
   "source": [
    "2-2. EfficientDet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6a0b6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 10s 10s/step - loss: 1611.2268 - loss_class: 1608.0566 - loss_bbox: 3.1687\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(10, 100, 21), (10, 100, 4)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "x = tf.keras.layers.Input(shape = [*image_shape, 3], name = \"x_true\")\n",
    "out = tfdet.model.detector.effdet_d4(x, n_class = n_class, scale = [32, 64, 128, 256, 512], ratio = [0.5, 1, 2], octave = 3, weights = \"imagenet\")\n",
    "\n",
    "model = tfdet.model.train.effdet.train_model(x, *out,\n",
    "                                             proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)\n",
    "model.compile()\n",
    "model.evaluate(bbox_pipe)\n",
    "[p.shape for p in model.predict(bbox_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc3af318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 100, 21), (10, 100, 4)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict model\n",
    "nms_out = tfdet.model.postprocess.effdet.FilterDetection(proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)(out)\n",
    "model = tf.keras.Model(x, nms_out)\n",
    "[p.shape for p in model.predict(bbox_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de920ee",
   "metadata": {},
   "source": [
    "2-3. EfficientDet-Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cc5286b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 6s 6s/step - loss: 3188.5142 - loss_class: 3186.2808 - loss_bbox: 2.2331\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(10, 100, 21), (10, 100, 4)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "x = tf.keras.layers.Input(shape = [*image_shape, 3], name = \"x_true\")\n",
    "out = tfdet.model.detector.effdet_lite_d4(x, n_class = n_class, scale = [32, 64, 128, 256, 512], ratio = [0.5, 1, 2], octave = 3, weights = \"imagenet\")\n",
    "\n",
    "model = tfdet.model.train.effdet.train_model(x, *out,\n",
    "                                             proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)\n",
    "model.compile()\n",
    "model.evaluate(bbox_pipe)\n",
    "[p.shape for p in model.predict(bbox_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26d30415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 100, 21), (10, 100, 4)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict model\n",
    "nms_out = tfdet.model.postprocess.effdet.FilterDetection(proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)(out)\n",
    "model = tf.keras.Model(x, nms_out)\n",
    "[p.shape for p in model.predict(bbox_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242f869f",
   "metadata": {},
   "source": [
    "2-4. Yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4eff0bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step - loss: 273.2581 - loss_score: 262.8026 - loss_class: 7.7024 - loss_bbox: 2.7532\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(10, 100, 21), (10, 100, 4)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "x = tf.keras.layers.Input(shape = [*image_shape, 3], name = \"x_true\")\n",
    "out = tfdet.model.detector.yolo_v4(x, n_class = n_class, size = [[ 10, 13], [ 16,  30], [ 33,  23], \n",
    "                                                                 [ 30, 61], [ 62,  45], [ 59, 119], \n",
    "                                                                 [116, 90], [156, 198], [373, 326]], weights = \"darknet\")\n",
    "\n",
    "model = tfdet.model.train.yolo.train_model(x, *out,\n",
    "                                           proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)\n",
    "model.compile()\n",
    "model.evaluate(bbox_pipe)\n",
    "[p.shape for p in model.predict(bbox_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4acecd03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 100, 21), (10, 100, 4)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict model\n",
    "nms_out = tfdet.model.postprocess.yolo.FilterDetection(proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)(out)\n",
    "model = tf.keras.Model(x, nms_out)\n",
    "[p.shape for p in model.predict(bbox_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897480e9",
   "metadata": {},
   "source": [
    "2-5. FCOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f97450a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 6s 6s/step - loss: 14003.8535 - loss_class: 13999.4873 - loss_bbox: 2.7739 - loss_conf: 1.5919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(10, 100, 21), (10, 100, 4)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "x = tf.keras.layers.Input(shape = [*image_shape, 3], name = \"x_true\")\n",
    "feature = tfdet.model.backbone.resnet50(x, frozen_stages = 1, weights = \"imagenet_v2\")\n",
    "\n",
    "out = tfdet.model.detector.fcos(feature, image_shape = tf.shape(x)[1:3], n_class = n_class)\n",
    "\n",
    "model = tfdet.model.train.fcos.train_model(x, *out,\n",
    "                                           proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)\n",
    "model.compile()\n",
    "model.evaluate(bbox_pipe)\n",
    "[p.shape for p in model.predict(bbox_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65fd2c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 100, 21), (10, 100, 4)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict model\n",
    "nms_out = tfdet.model.postprocess.fcos.FilterDetection(proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)(out)\n",
    "model = tf.keras.Model(x, nms_out)\n",
    "[p.shape for p in model.predict(bbox_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfb288f",
   "metadata": {},
   "source": [
    "## 3. Build 2-Stage Object Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02599492",
   "metadata": {},
   "source": [
    "3-1. Faster R-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "950f8878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step - loss: 7.0395 - loss_rpn_class: 2.0582 - loss_rpn_bbox: 1.7673 - loss_roi_class: 2.7224 - loss_roi_bbox: 0.4916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(10, 100, 21), (10, 100, 4)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "x = tf.keras.layers.Input(shape = [*image_shape, 3], name = \"x_true\")\n",
    "feature = tfdet.model.backbone.resnet50(x, frozen_stages = 1, weights = \"imagenet_v2\")\n",
    "\n",
    "out = tfdet.model.detector.faster_rcnn(feature, image_shape = tf.shape(x)[1:3], n_class = n_class, scale = [32, 64, 128, 256, 512], ratio = [0.5, 1, 2],\n",
    "                                       train = True, proposal_count = 2000)\n",
    "\n",
    "model = tfdet.model.train.rcnn.train_model(x, *out,\n",
    "                                           proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)\n",
    "model.compile()\n",
    "model.evaluate(bbox_pipe)\n",
    "[p.shape for p in model.predict(bbox_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96b3aacc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 100, 21), (10, 100, 4)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict model\n",
    "x = tf.keras.layers.Input(shape = [*image_shape, 3], name = \"x_true\")\n",
    "feature = tfdet.model.backbone.resnet50(x, frozen_stages = 1, weights = \"imagenet_v2\")\n",
    "\n",
    "out = tfdet.model.detector.faster_rcnn(feature, image_shape = tf.shape(x)[1:3], n_class = n_class, scale = [32, 64, 128, 256, 512], ratio = [0.5, 1, 2], \n",
    "                                       proposal_count = 1000)\n",
    "nms_out = tfdet.model.postprocess.rcnn.FilterDetection(proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)(out)\n",
    "model = tf.keras.Model(x, nms_out)\n",
    "[p.shape for p in model.predict(bbox_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08213dc",
   "metadata": {},
   "source": [
    "3-2. Mask R-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf74793e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 7s 7s/step - loss: 7.5038 - loss_rpn_class: 2.1454 - loss_rpn_bbox: 1.7169 - loss_roi_class: 2.7175 - loss_roi_bbox: 0.0469 - loss_roi_mask: 0.8771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(10, 100, 21), (10, 100, 4), (10, 100, 14, 14, 1)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "x = tf.keras.layers.Input(shape = [*image_shape, 3], name = \"x_true\")\n",
    "feature = tfdet.model.backbone.resnet50(x, frozen_stages = 1, weights = \"imagenet_v2\")\n",
    "\n",
    "out = tfdet.model.detector.mask_rcnn(feature, image_shape = tf.shape(x)[1:3], n_class = n_class, scale = [32, 64, 128, 256, 512], ratio = [0.5, 1, 2],\n",
    "                                     train = True, proposal_count = 2000, mask_pool_size = 7)\n",
    "\n",
    "model = tfdet.model.train.rcnn.train_model(x, *out,\n",
    "                                           proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)\n",
    "model.compile()\n",
    "model.evaluate(mask_pipe)\n",
    "[p.shape for p in model.predict(mask_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ad7cd68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 100, 21), (10, 100, 4), (10, 100, 14, 14, 1)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict model\n",
    "x = tf.keras.layers.Input(shape = [*image_shape, 3], name = \"x_true\")\n",
    "feature = tfdet.model.backbone.resnet50(x, frozen_stages = 1, weights = \"imagenet_v2\")\n",
    "\n",
    "out = tfdet.model.detector.mask_rcnn(feature, image_shape = tf.shape(x)[1:3], n_class = n_class, scale = [32, 64, 128, 256, 512], ratio = [0.5, 1, 2], \n",
    "                                     proposal_count = 1000, mask_pool_size = 7)\n",
    "nms_out = tfdet.model.postprocess.rcnn.FilterDetection(proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)(out)\n",
    "model = tf.keras.Model(x, nms_out)\n",
    "[p.shape for p in model.predict(mask_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1847466",
   "metadata": {},
   "source": [
    "3-3. Cascade R-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ac8b287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 6s 6s/step - loss: 8.9068 - loss_rpn_class: 1.9914 - loss_rpn_bbox: 1.7093 - loss_roi_class_1: 2.4549 - loss_roi_bbox_1: 0.3867 - loss_roi_class_2: 1.4484 - loss_roi_bbox_2: 0.0951 - loss_roi_class_3: 0.8084 - loss_roi_bbox_3: 0.0127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(10, 100, 21), (10, 100, 4)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "x = tf.keras.layers.Input(shape = [*image_shape, 3], name = \"x_true\")\n",
    "feature = tfdet.model.backbone.resnet50(x, frozen_stages = 1, weights = \"imagenet_v2\")\n",
    "\n",
    "out = tfdet.model.detector.cascade_rcnn(feature, image_shape = tf.shape(x)[1:3], n_class = n_class, scale = [32, 64, 128, 256, 512], ratio = [0.5, 1, 2],\n",
    "                                        train = True, proposal_count = 2000)\n",
    "\n",
    "model = tfdet.model.train.rcnn.train_model(x, *out,\n",
    "                                           proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)\n",
    "model.compile()\n",
    "model.evaluate(bbox_pipe)\n",
    "[p.shape for p in model.predict(bbox_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25894ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 100, 21), (10, 100, 4)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict model\n",
    "x = tf.keras.layers.Input(shape = [*image_shape, 3], name = \"x_true\")\n",
    "feature = tfdet.model.backbone.resnet50(x, frozen_stages = 1, weights = \"imagenet_v2\")\n",
    "\n",
    "out = tfdet.model.detector.cascade_rcnn(feature, image_shape = tf.shape(x)[1:3], n_class = n_class, scale = [32, 64, 128, 256, 512], ratio = [0.5, 1, 2], \n",
    "                                        proposal_count = 1000)\n",
    "nms_out = tfdet.model.postprocess.rcnn.FilterDetection(proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)(out)\n",
    "model = tf.keras.Model(x, nms_out)\n",
    "[p.shape for p in model.predict(bbox_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f22913a",
   "metadata": {},
   "source": [
    "3-4. Hybrid Task Cascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "889d690e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 18s 18s/step - loss: 14.2033 - loss_rpn_class: 2.0876 - loss_rpn_bbox: 1.2727 - loss_roi_class_1: 2.9819 - loss_roi_bbox_1: 0.3287 - loss_roi_mask_1: 1.4059 - loss_roi_class_2: 1.6842 - loss_roi_bbox_2: 0.0829 - loss_roi_mask_2: 0.6197 - loss_roi_class_3: 1.0079 - loss_roi_bbox_3: 0.0265 - loss_roi_mask_3: 0.2636 - loss_semantic: 2.4416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(10, 100, 21), (10, 100, 4), (10, 100, 14, 14, 1)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "x = tf.keras.layers.Input(shape = [*image_shape, 3], name = \"x_true\")\n",
    "feature = tfdet.model.backbone.resnet50(x, frozen_stages = 1, weights = \"imagenet_v2\")\n",
    "\n",
    "out = tfdet.model.detector.hybrid_task_cascade(feature, image_shape = tf.shape(x)[1:3], n_class = n_class, scale = [32, 64, 128, 256, 512], ratio = [0.5, 1, 2],\n",
    "                                               train = True, proposal_count = 2000, mask_pool_size = 7)\n",
    "\n",
    "model = tfdet.model.train.rcnn.train_model(x, *out,\n",
    "                                           proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)\n",
    "model.compile()\n",
    "model.evaluate(mask_pipe)\n",
    "[p.shape for p in model.predict(mask_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0b4b75f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 100, 21), (10, 100, 4), (10, 100, 14, 14, 1)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict model\n",
    "x = tf.keras.layers.Input(shape = [*image_shape, 3], name = \"x_true\")\n",
    "feature = tfdet.model.backbone.resnet50(x, frozen_stages = 1, weights = \"imagenet_v2\")\n",
    "\n",
    "out = tfdet.model.detector.hybrid_task_cascade(feature, image_shape = tf.shape(x)[1:3], n_class = n_class, scale = [32, 64, 128, 256, 512], ratio = [0.5, 1, 2], \n",
    "                                               proposal_count = 1000, mask_pool_size = 7)\n",
    "nms_out = tfdet.model.postprocess.rcnn.FilterDetection(proposal_count = 100, iou_threshold = 0.5, score_threshold = 0.05)(out)\n",
    "model = tf.keras.Model(x, nms_out)\n",
    "[p.shape for p in model.predict(mask_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6203405",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
