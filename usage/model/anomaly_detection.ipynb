{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5d46508",
   "metadata": {},
   "source": [
    "# 0. Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13afde46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./tfdet\"):\n",
    "    !git clone -q http://github.com/burf/tfdetection.git\n",
    "    !mv ./tfdetection/tfdet ./tfdet\n",
    "    !rm -rf ./tfdetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "876a4a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore warning\n",
    "import warnings, os\n",
    "warnings.filterwarnings(action = \"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "import tfdet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916a858c",
   "metadata": {},
   "source": [
    "# 1. Init Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac7480f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample dataset\n",
    "import numpy as np\n",
    "\n",
    "image_shape = [32, 32]\n",
    "sampling_size = 550\n",
    "total_data_size = 4\n",
    "batch_size = 1\n",
    "\n",
    "def load():\n",
    "    image = np.random.random([*image_shape, 3]).astype(np.float32)\n",
    "    return image\n",
    "\n",
    "def generator():\n",
    "    for _ in range(total_data_size):\n",
    "        yield load()\n",
    "        \n",
    "feature_pipe = tf.data.Dataset.from_generator(generator, tf.float32).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774ce7d7",
   "metadata": {},
   "source": [
    "# 2. Build Anomaly Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14694b1e",
   "metadata": {},
   "source": [
    "2-1. Feature-Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c9ccf03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 174ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(4, 1), (4, 32, 32, 1)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.keras.layers.Input(shape = [*image_shape, 3])\n",
    "out = tfdet.model.backbone.wide_resnet50_2_torch(x, weights = \"imagenet\", indices = [0, 1, 2])\n",
    "model = tf.keras.Model(x, out)\n",
    "feature = model.predict(feature_pipe)\n",
    "\n",
    "n_feature = np.sum([np.shape(f)[-1] for f in feature])\n",
    "sampling_index = np.random.choice(np.arange(n_feature), sampling_size, replace = False)\n",
    "feature_vector = tfdet.model.train.padim.train(feature, sampling_index = sampling_index, memory_reduce = False) #memory_reduce is a tradeoff between accuracy and memory\n",
    "\n",
    "score, mask = tfdet.model.detector.padim(out, feature_vector, image_shape = image_shape, sampling_index = sampling_index, memory_reduce = False) #align memory_reduce with train in test\n",
    "filtered_out = tfdet.model.postprocess.padim.FilterDetection(threshold = 0.5)([score, mask]) #threshold > tfdet.util.get_threshold(label, pred)\n",
    "\n",
    "model = tf.keras.Model(x, filtered_out)\n",
    "[p.shape for p in model.predict(feature_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e209094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(4, 1), (4, 32, 32, 1)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.keras.layers.Input(shape = [*image_shape, 3])\n",
    "out = tfdet.model.backbone.wide_resnet50_2_torch(x, weights = \"imagenet\", indices = [0, 1, 2])\n",
    "model = tf.keras.Model(x, out)\n",
    "feature = model.predict(feature_pipe)\n",
    "\n",
    "n_feature = np.sum([np.shape(f)[-1] for f in feature])\n",
    "sampling_index = np.random.choice(np.arange(n_feature), sampling_size, replace = False)\n",
    "feature_vector = tfdet.model.train.patch_core.train(feature, sampling_index = sampling_index, memory_reduce = False) #memory_reduce is a tradeoff between accuracy and memory\n",
    "\n",
    "score, mask = tfdet.model.detector.patch_core(out, feature_vector, image_shape = image_shape, k = 9, sampling_index = sampling_index, memory_reduce = False) #align memory_reduce with train in test\n",
    "filtered_out = tfdet.model.postprocess.patch_core.FilterDetection(threshold = 0.5)([score, mask]) #threshold > tfdet.util.get_threshold(label, pred)\n",
    "\n",
    "model = tf.keras.Model(x, filtered_out)\n",
    "[p.shape for p in model.predict(feature_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2444c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(4, 1), (4, 32, 32, 1)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.keras.layers.Input(shape = [*image_shape, 3])\n",
    "out = tfdet.model.backbone.wide_resnet50_2_torch(x, weights = \"imagenet\", indices = [0, 1, 2])\n",
    "model = tf.keras.Model(x, out)\n",
    "feature = model.predict(feature_pipe)\n",
    "\n",
    "n_feature = np.sum([np.shape(f)[-1] for f in feature])\n",
    "sampling_index = np.random.choice(np.arange(n_feature), sampling_size, replace = False)\n",
    "feature_vector = tfdet.model.train.spade.train(feature, sampling_index = sampling_index) #memory_reduce is a tradeoff between accuracy and memory\n",
    "\n",
    "score, mask = tfdet.model.detector.spade(out, feature_vector, image_shape = image_shape, k = 50, sampling_index = sampling_index) #align memory_reduce with train in test\n",
    "filtered_out = tfdet.model.postprocess.spade.FilterDetection(threshold = 0.5)([score, mask]) #threshold > tfdet.util.get_threshold(label, pred)\n",
    "\n",
    "model = tf.keras.Model(x, filtered_out)\n",
    "[p.shape for p in model.predict(feature_pipe, verbose = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984bf2e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
